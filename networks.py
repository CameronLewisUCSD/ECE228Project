#In this file we will place the architecture of our networkimport torch
#hitest:
import torch
import torch.nn as nn
import torch.nn.functional as f
import numpy as np


# ======== This network is for data of dimension 100x87 (4 s) =================
class Encoder(nn.Module):
    """
    Description: Encoder layers of autoencoder model; encodes input data
    (spectrograms) into the latent feature space.
    Inputs:
        - Input data (spectrograms)
    Outputs:
        - Latent feature space data
    """
    def __init__(self):
        super(Encoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 8, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.ReLU(True),
            nn.Conv2d(8, 16, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.ReLU(True),
            nn.Conv2d(16, 32, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.ReLU(True),
            nn.Conv2d(32, 64, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.ReLU(True),
            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=(1,0)),
            nn.ReLU(True),

            nn.Flatten(),
            nn.Linear(1152, 9),
            nn.ReLU(True)
        )

    def forward(self, x):
        x = self.encoder(x)
        return x


class Decoder(nn.Module):
    """
    Description: Decoder layers of autoencoder model; reconstructs encoder
    inputs using the latent features generated by the encoder.
    Inputs:
        - Latent space data
    Outputs:
        - Reconstructed data
    """
    def __init__(self):
        super(Decoder, self).__init__()
        self.latent2dec = nn.Sequential(
            nn.Linear(9, 1152),
            nn.ReLU(True)
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=(3,3), stride=(2,2), padding=(1,0)), # <---- Experimental
            nn.ReLU(True),  # <---- Experimental
            nn.ConvTranspose2d(64, 32, kernel_size=(3,3), stride=(2,2), padding=(0,1)),
            nn.ReLU(True),
            nn.ConvTranspose2d(32, 16, kernel_size=(3,3), stride=(2,2), padding=(0,1)),
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, kernel_size=(3,3), stride=(2,2), padding=(0,0)),
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 1, kernel_size=(3,3), stride=(2,2), padding=(0,1)),
        )

    def forward(self, x):
        x = self.latent2dec(x)
        x = x.view(-1, 128, 3, 3)
        x = self.decoder(x)
        return x[:,:,4:-4,1:]


class AEC(nn.Module):
    """
    Description: Autoencoder model; combines encoder and decoder layers.
    Inputs:
        - Input data (spectrograms)
    Outputs:
        - Reconstructed data
        - Latent space data
    """
    def __init__(self):
        super(AEC, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

    def forward(self, x):
        z = self.encoder(x)
        x = self.decoder(z)
        return x, z


def init_weights(m):
    """
    Description: Initializes weights with the Glorot Uniform distribution.
    Inputs:
        - Latent space data
    Outputs:
        - Reconstructed data
    """
    if type(m) in [nn.Linear, nn.Conv2d, nn.ConvTranspose2d]:
        torch.nn.init.xavier_uniform_(m.weight)
        m.bias.data.fill_(0.01)


class ClusteringLayer(nn.Module):
    """
    Description: Generates soft cluster assignments using latent features as
    input.
    Arguments:
        - n_clusters: User-defined
        - n_features: Must match output dimension of encoder.
        - alpha: Exponential factor (default: 1.0)
        - weights: Initial values for the cluster centroids
    Inputs:
        Encoded data (output of encoder)
    Outputs:
        Soft cluster assignments
    """
    def __init__(self, n_clusters, n_features=9, alpha=1.0, weights=None):
        super(ClusteringLayer, self).__init__()
        self.n_features = n_features
        self.n_clusters = n_clusters
        self.alpha = alpha
        if weights is None:
            initial_weights = torch.zeros(
                self.n_clusters, self.n_features, dtype=torch.float
            )
            nn.init.xavier_uniform_(initial_weights)
        else:
            initial_weights = weights
        self.weights = nn.Parameter(initial_weights)

    def forward(self, x):
        x = x.unsqueeze(1) - self.weights
        x = torch.mul(x, x)
        x = torch.sum(x, dim=2)
        x = 1.0 + (x / self.alpha)
        x = 1.0 / x
        x = x ** ((self.alpha +1.0) / 2.0)
        x = torch.t(x) / torch.sum(x, dim=1)
        x = torch.t(x)
        return x


class DEC(nn.Module):
    """Description: Deep Embedded Clustering Model; combines autoencoder with
    clustering layer to generate end-to-end deep embedded clustering neural
    network model.

    Parameters
    ----------
    n_clusters : int
        Number of clusters

    Returns
    -------
    q : array
        Soft cluster assignments

    x : array
        Reconstructed data

    z : array
        Latent space data
    """
    def __init__(self, n_clusters):
        super(DEC, self).__init__()
        self.n_clusters = n_clusters
        self.encoder = Encoder()
        self.decoder = Decoder()
        self.clustering = ClusteringLayer(self.n_clusters)

    def forward(self, x):
        z = self.encoder(x)
        x = self.decoder(z)
        q = self.clustering(z)
        return q, x, z
    
class UNET(nn.Module):
    """
    Description: 
    Inputs:
        - Input data (spectrograms)
    Outputs:
        - Reconstructed data
        - Latent space data
    """
    def __init__(self):
        super(UNET, self).__init__()

        #down
        self.c11 = nn.Conv2d(1,8, kernel_size=(3,3),padding=(1,1))
        self.c12 = nn.Conv2d(8,8, kernel_size=(3,3),padding=(1,1),stride=(2,2))
        self.pool1=nn.MaxPool2d((2, 2),padding=(1,1))
        self.drop1=nn.Dropout(.25)
        
        self.c21 = nn.Conv2d(8,16, kernel_size=(3,3),padding=(1,1))
        self.c22 = nn.Conv2d(16,16, kernel_size=(3,3),padding=(1,1))
        self.pool2=nn.MaxPool2d((2, 2))
        self.drop2=nn.Dropout(.5)
        
        self.c31 = nn.Conv2d(16,32, kernel_size=(3,3), padding=(1,1))
        self.c32 = nn.Conv2d(32,32, kernel_size=(3,3),padding=(1,1))
        self.pool3=nn.MaxPool2d((2, 2))
        self.drop3=nn.Dropout(.5)
        
        
        self.c41 = nn.Conv2d(32,64, kernel_size=(3,3), padding=(2,1))
        self.c42 = nn.Conv2d(64,64, kernel_size=(3,3),padding=(1,1))
        self.pool4=nn.MaxPool2d((2, 2))
        self.drop4=nn.Dropout(.5)
        
        self.convmid1 = nn.Conv2d(64,128, kernel_size=(3,3), padding=(1,1))
        self.convmid2= nn.Conv2d(128,128, kernel_size=(3,3), padding=(1,1))
        
        
        self.f1 = nn.Flatten()
        self.l1 = nn.Linear(1152,9)
        
        
        self.l2 = nn.Linear(9,1152)
    
        
        self.dc41=nn.ConvTranspose2d(128, 64, kernel_size=(2,2), stride=(2,2),padding=(1,1))
        self.ddrop4=nn.Dropout(.5)
        self.dc42=nn.Conv2d(128,64, kernel_size=(3,3),padding=(1,1))
        self.dc43=nn.Conv2d(64,64, kernel_size=(3,3),padding=(1,1))
        
        
        self.dc31=nn.ConvTranspose2d(64, 32, kernel_size=(2,2), stride=(2,2),padding=(1,1))     
        self.ddrop3=nn.Dropout(.5)
        self.dc32=nn.Conv2d(64,32, kernel_size=(3,3),padding=(1,1))
        self.dc33=nn.Conv2d(32,32, kernel_size=(3,3),padding=(1,1))
        
        self.dc21=nn.ConvTranspose2d(32, 16, kernel_size=(3,3),stride=(2,2),padding=(1,1))
        self.ddrop2=nn.Dropout(.5)
        self.dc22=nn.Conv2d(32,16, kernel_size=(3,3),padding=(1,1))
        self.dc23=nn.Conv2d(16,16, kernel_size=(3,3),padding=(1,1))
        
        
        self.dc11=nn.ConvTranspose2d(16, 8, kernel_size=(3,3),stride=(4,4),padding=(1,1))
        self.ddrop1=nn.Dropout(.5)
        self.dc12=nn.Conv2d(16,8, kernel_size=(1,1))
        self.dc13=nn.Conv2d(8,8, kernel_size=(1,1))
        
        
        #self.dc1=nn.ConvTranspose2d(8, 1, kernel_size=(3,3))#, stride=(2,2), padding=(0,1))
        self.out=nn.Conv2d(8,1, kernel_size=(1,1))
        

    def forward(self, x):
        #down
        x1 = f.relu(self.c11(x))
        x1pre=x1
        x1 = f.relu(self.c12(x1))

        x1=self.pool1(x1)
        x1=self.drop1(x1)
        
        
        x2 = f.relu(self.c21(x1))
        x2 = f.relu(self.c22(x2))
        x2pre=x2
        x2=self.pool2(x2)
        x2=self.drop2(x2)
        
        x3 = f.relu(self.c31(x2))
        x3 = f.relu(self.c32(x3))
        x3pre=x3
        x3 = self.pool3(x3)
        x3 = self.drop3(x3)
        
        
                
        x4 = f.relu(self.c41(x3))
        x4 = f.relu(self.c42(x4))
        x4pre=x4
        x4 = self.pool4(x4)
        x4 = self.drop4(x4)
        
        
        xmid=self.convmid1(x4)
        xmid=self.convmid2(xmid)
        
        f1 = self.f1(xmid)
        latent = f.relu(self.l1(f1))
        l2 = f.relu(self.l2(latent))
        x = l2.view(-1, 128, 3, 3)
        
        
        xd4=self.dc41(x)
        diffY = x4pre.size()[2] - xd4.size()[2]
        diffX = x4pre.size()[3] - xd4.size()[3] 
        xd4 = f.pad(xd4,[diffX//2, diffX -diffX//2, diffY//2, diffY- diffY//2])
        xd4=torch.cat([xd4, x4pre],dim=1)
        xd4=self.ddrop4(xd4)
        xd4=f.relu(self.dc42(xd4))
        xd4=f.relu(self.dc43(xd4))
        
        
        
        xd3=self.dc31(xd4)
        diffY = x3pre.size()[2] - xd3.size()[2]
        diffX = x3pre.size()[3] - xd3.size()[3] 
        xd3 = f.pad(xd3,[diffX//2, diffX -diffX//2, diffY//2, diffY- diffY//2])

        xd3=torch.cat([xd3, x3pre],dim=1)
        xd3=self.ddrop3(xd3)
        xd3=f.relu(self.dc32(xd3))
        xd3=f.relu(self.dc33(xd3))

        

        
        xd2=self.dc21(xd3)
        
        diffY = x2pre.size()[2] - xd2.size()[2]
        diffX = x2pre.size()[3] - xd2.size()[3] 
        xd2 = f.pad(xd2,[diffX//2, diffX -diffX//2, diffY//2, diffY- diffY//2])
        xd2=torch.cat([xd2, x2pre],dim=1)
        xd2=self.ddrop2(xd2)
        xd2=f.relu(self.dc22(xd2))
        xd2=f.relu(self.dc23(xd2))

    
    
        xd1=self.dc11(xd2)
        diffY = x1pre.size()[2] - xd1.size()[2]
        diffX = x1pre.size()[3] - xd1.size()[3] 
        xd1 = f.pad(xd1,[diffX//2, diffX -diffX//2, diffY//2, diffY- diffY//2])
        xd1=torch.cat([xd1, x1pre],dim=1)
        xd1=self.ddrop1(xd1)
        xd1=f.relu(self.dc12(xd1))
        xd1=f.relu(self.dc13(xd1))
        
        out=self.out(xd1)
        return out, latent
